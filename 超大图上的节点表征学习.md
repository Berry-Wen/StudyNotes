# 训练更深和更大的图神经网络
## 引言
深度学习的成功经验告诉我们，更多的训练数据、更深的网络结构能够达到更高的性能。然而，普通的基于 SGD（随机梯度下降）的方法在训练大规模 GNN（图神经网络）时面临着两个难以忍受的问题（资源消耗随图神经网络层数呈指数型增长）：训练时间长、消耗空间大。  
为了降低训练模型时的资源消耗、提高训练速度，进而拓展图神经网络模型的泛用性，提出更高效的训练方法是非常有必要的。综上，本文将介绍并比较几种主流的新训练方法，并对其中最有效的 Cluster-GCN 方法开展 Python 实践。  
## 任务回顾：图节点表征学习
GNN 能够应用于许多基于图的任务，比如节点分类、链接预测和推荐系统等，而这些任务的完成主要依赖于图节点表征（node embedding）学习的好坏。  
以流行的图神经网络模型 GCN 为例，它 使用一个图卷积运算（收集相邻节点的表征）逐层获得节点表征，随后是一层或几层的线性变换和非线性激活，最后一层表征应用于最终任务。为了方便之后训练方法的讲解，我们先对训练过程中涉及到的概念进行定义，如下所示。  
给定一个图 $G=(\mathcal{V}, \mathcal{E}, A)$，它由 $N=|\mathcal{V}|$ 个节点和 $|\mathcal{E}|$ 条边组成，其邻接矩阵记为 $A$，其节点属性记为 $X \in \mathbb{R}^{N \times F}$，$F$ 表示节点属性的维度。一个 $L$ 层的图卷积神经网络由 $L$ 个图卷积层组成，每一层都通过聚合邻接节点的上一层的表征来生成中心节点的当前层的表征：  
$$
Z^{(l+1)}=A^{\prime} X^{(l)} W^{(l)}, X^{(l+1)}=\sigma\left(Z^{(l+1)}\right)
\tag{1}
$$
其中 $X^{(l)} \in \mathbb{R}^{N \times F_{l}}$ 表示第 $l$ 层 $N$ 个节点的表征，并且有$X^{(0)}=X$。$A^{\prime}$ 是归一化和规范化后的邻接矩阵，$W^{(l)} \in \mathbb{R}^{F_{l} \times F_{l+1}}$是权重矩阵，也就是要训练的参数。为了简单起见，我们假设所有层的表征维度都是一样的，即 $\left(F_{1}=\cdots=F_{L}=F\right)$。激活函数 $\sigma(\cdot)$ 通常被设定为`ReLU`。  

当图神经网络应用于半监督节点分类任务时，训练的目标是通过最小化损失函数来学习公式(1)中的权重矩阵：  
$$
\mathcal{L}=\frac{1}{\left|\mathcal{Y}_{L}\right|} \sum_{i \in \mathcal{Y}_{L}} \operatorname{loss}\left(y_{i}, z_{i}^{L}\right)
\tag{2}
$$
其中，$\mathcal{Y}_{L}$ 是节点类别；$z_{i}^{(L)}$ 是 $Z^{(L)}$ 的第 $i$ 行，表示对节点 $i$ 的预测，节点 $i$ 的真实类别为 $y_{i}$。在实际应用中，交叉熵损失通常用于多类或多标签问题的节点分类。  
## GCN 训练算法
`图神经网络的特点`：与其他神经网络的样本训练损失可独立计算不同，GCN中单个样本的训练损失依赖于大量的其他节点，特别是在GCN深入的时候。这种节点依赖关系导致 GCN 训练缓慢，而且需要将所有节点表征存储在内存中（很多设备没有那么大的内存，导致无法训练）。  
`训练算法评价标准`：①内存需求（memory）；②每个 epoch 需要的时间（time per epoch）；③每个 epoch 的收敛速度（convergence）；其中，内存需求直接限制了算法的可扩展性，后两者结合起来将决定训练速度。在接下来的讨论中，我们用 $N$ 表示图中的节点数，$F$ 表示嵌入维数，$L$ 表示层数来分析 GCN 训练算法的有效性。  
### Full-batch gradient descent
最早的训练方法，它需要同时计算所有节点的表征（内存要求高），空间复杂度高 O($NFL$)。 它需要计算出训练集中所有节点的损失后才会产生梯度进行一次参数更新。该算法每次更新的参数时有效的，但是每次更新所耗费的时间太多。  
`总结`：memory: bad; time per epoch: good; convergence: bad  
### Mini-batch SGD
SGD 方法是在计算单个节点的损失后就产生梯度进行一次参数更新，迭代速度会很快，但是每个迭代的效果可能不稳定，甚至达不到局部最优。为了平衡迭代效果和速度，学者提出了 Mini-batch 的思想，就是将 N 个样本作为一个 batch 去迭代一次参数。如果 N=1，那该算法与 SGD 相同，若 N=样本总数，那该算法与 Full-batch 相同。  
Mini-batch SGD 方法在训练大规模图神经网络的时候，会随机抽取一些节点组成子图，然后基于这些子图去构建节点特征进而迭代参数。优点是，子图所占据的空间小，参数的更新频率会加快。  
但是，每个 epoch 的迭代效果会比较差，而且速度很慢，甚至低于 Full-bath。这是因为，节点实际上受邻近节点的影响较大，而随机选择会导致节点的抽样邻居实际距离较远（图通常大且稀疏）。也就是说，因为随机抽样的缘故，很多对距离较远的邻居的计算实际上是低效的（二八原则），“表征利用率” 较低，做了很多无用的计算（领域扩展问题）。  
`总结`：memory: good; time per epoch: bad; convergence: good
### Cluster-GCN
Cluster-GCN方法是由这样的问题驱动的：我们能否找到一种将节点分成多个 batch 的方式，对应地将图划分成多个子图，使得表征利用率最大？因为表征利用率与 batch 内边的数量呈正相关，理想的划分目标应该是 batch 内的边尽可能多，batch之间的边尽可能少。基于这一点，我们将SGD图神经网络训练的效率与图聚类算法联系起来。  
对于一个图 $G$，我们可以将其节点划分为 $c$ 个簇，对应的我们有 $c$ 个子图，子图中由其节点和对应的边组成。这些簇的簇内边的数量远多于簇间边的数量，这保证了 $L$ 跳（L-hop）远的邻接节点大概率仍然在同一个簇中，可以避免巨大范围的邻域扩展，如下图所示：  
<img src="F:\学习总结\Method-and-Technology\images\Clustr-GCN.png" alt="Clustr-GCN" style="zoom:80%;" />    
`总结`：memory: good; time per epoch: good; convergence: good  
尽管简单 Cluster-GCN 方法可以做到更低的计算和内存复杂度，但它仍存在两个潜在问题：  
* 图被分割后，一些边被移除，性能可能因此会受到影响。  
* 图聚类算法倾向于将相似的节点聚集在一起。因此，单个簇中节点的类别分布可能与原始数据集不同，导致对梯度的估计有偏差。  
为了解决上述问题，Cluster-GCN论文提出了一种随机多簇方法，此方法首先将图划分为 $p$ 个簇，在构建一个batch时，不是只使用一个簇 ， 而是使用随机选择的 $q$ 个簇，如下所示：  
<img src="F:\学习总结\Method-and-Technology\images\Multiple-clusters.png" alt="Clustr-GCN" style="zoom:80%;" />    
随机多分区相比单独簇的效果比较，如下所示：  
<img src="F:\学习总结\Method-and-Technology\images\GCN-compare.png" alt="Clustr-GCN" style="zoom:80%;" />  
## Cluster-GCN实践
PyG 为 Cluster-GCN 提出的训练方式和神经网络的构建提供了良好的支持。我们无需在意图节点是如何被划分成多个簇的，PyG 允许我们像训练普通神经网络一样在超大图上训练图神经网络。  
### 数据集载入和分析
```python
from torch_geometric.datasets import Reddit
from torch_geometric.data import ClusterData, ClusterLoader, NeighborSampler

dataset = Reddit('dataset/Reddit') # 包含了属于不同社区的Reddit帖子数据 1.3G
data = dataset[0]
print(dataset.num_classes) # 41
print(data.num_nodes) # 232965
print(data.num_edges) # 114615873
print(data.num_features) # 602
```
若无法直接通过程序下载，可手动下载压缩包，将解压后的两个文件放入 Reddit/raw 文件夹中。  
### 图节点聚类与数据加载器生成
```python
cluster_data = ClusterData(data, num_parts=1500, recursive=False, save_dir=dataset.processed_dir)
# 耗时较长（30分钟）；空间要求高，可设置任意盘（优先固态硬盘）至少130G的虚拟内存
# num_parts指要聚成多少簇，与Kmeans聚类算法的超参数K值相同

train_loader = ClusterLoader(cluster_data, batch_size=20, shuffle=True, num_workers=12)
# batchsize指每次随机选择多少个簇作为一个batch进行运算
# num_worders指并行运算的工作单元，建议设置成自己计算机的核数目，否则可能无法计算

subgraph_loader = NeighborSampler(data.edge_index, sizes=[-1], batch_size=1024, shuffle=False, num_workers=12)
# 不对图节点聚类，计算一个batch中的节点表征需要计算所有节点的距离从0到L的邻居节点
# sizes用来设置对节点抽样的邻居数目，若为-1，则说明抽样所有的邻居
```
设置虚拟内存的方法可参考文章 [如何设置win10系统的虚拟内存](https://baijiahao.baidu.com/s?id=1621157354219504755&wfr=spider&for=pc)  
### 图神经网络的构建
```python
class Net(torch.nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Net, self).__init__()
        self.convs = ModuleList( 
            [SAGEConv(in_channels, 128), # 设置隐藏层为128个神经元
             SAGEConv(128, out_channels)])

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs): # 可以列表形式被调用
            x = conv(x, edge_index)  # conv是定义的网络层 SAGEConv
            if i != len(self.convs) - 1: # i是索引值：0 1
                x = F.relu(x)
                x = F.dropout(x, p=0.5, training=self.training)
        return F.log_softmax(x, dim=-1)

    def inference(self, x_all): # 用作验证和测试，即应用
        pbar = tqdm(total=x_all.size(0) * len(self.convs))
        pbar.set_description('Evaluating')

        # Compute representations of nodes layer by layer, using *all*
        # available edges. This leads to faster computation in contrast to
        # immediately computing the final representations of each batch.
        for i, conv in enumerate(self.convs):
            xs = []
            for batch_size, n_id, adj in subgraph_loader:
                edge_index, _, size = adj.to(device)
                x = x_all[n_id].to(device)
                x_target = x[:size[1]]
                x = conv((x, x_target), edge_index)
                if i != len(self.convs) - 1:
                    x = F.relu(x)
                xs.append(x.cpu())
                pbar.update(batch_size)
            x_all = torch.cat(xs, dim=0)
        pbar.close()
        return x_all
```
可以看到此神经网络拥有 forward 和 inference 两个方法。forward 函数的定义与普通的图神经网络并无区别。inference 方法应用于推理阶段，为了获取更高的预测精度（可奢侈一些）。  
ModuleList 不同于之前使用过的 Sequential，它可以像普通的Python列表一样被索引。Sequential 是顺序容器。模块将按照它们在构造函数中被传递的顺序添加到它。  
### 训练、验证与测试
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net(dataset.num_features, dataset.num_classes).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.005)

def train():
    model.train()

    total_loss = total_nodes = 0
    for batch in train_loader:
        batch = batch.to(device)
        optimizer.zero_grad()
        out = model(batch.x, batch.edge_index)
        loss = F.nll_loss(out[batch.train_mask], batch.y[batch.train_mask])
        loss.backward()
        optimizer.step()
        nodes = batch.train_mask.sum().item()
        total_loss += loss.item() * nodes
        total_nodes += nodes
        
    return total_loss / total_nodes


@torch.no_grad()
def test():  # Inference should be performed on the full graph.
    model.eval()
    out = model.inference(data.x)
    y_pred = out.argmax(dim=-1)
    accs = []
    for mask in [data.train_mask, data.val_mask, data.test_mask]:
        correct = y_pred[mask].eq(data.y[mask]).sum().item()
        accs.append(correct / mask.sum().item())
    return accs

for epoch in range(1, 31):  #耗时较长
    loss = train()
    if epoch % 5 == 0:
        train_acc, val_acc, test_acc = test()
        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '
              f'Val: {val_acc:.4f}, test: {test_acc:.4f}')
    else:
        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')
# Epoch: 01, Loss: 1.1842
# Epoch: 02, Loss: 0.4907
# Epoch: 03, Loss: 0.3991
# Epoch: 04, Loss: 0.3621
# Evaluating: 100%|██████████| 465930/465930 [2:26:57<00:00, 52.84it/s]
# Epoch: 05, Loss: 0.3397, Train: 0.9594, Val: 0.9542, test: 0.9532
# ......
# Evaluating: 100%|██████████| 465930/465930 [32:30<00:00, 238.90it/s]
# Epoch: 30, Loss: 0.2331, Train: 0.9720, Val: 0.9543, test: 0.9513
```
在推理阶段，为了加快计算速度，需要使用 with torch.no_grad()或者@torch.no_grad() 语法，表明数据不需要计算梯度，也不会进行反向传播。  
### 拓展分析：聚类数目对训练过程和结果的影响
上文中，聚类数目为 1500 时，计算出来的测试准确率为 0.9513，每个 epoch 耗时约30分钟。  
我们测试当聚类数目为 1000 和 2000 时的结果，其他参数的设置均不变，结果如下可示：  
```python
cluster_data = ClusterData(data, num_parts=1000, recursive=False, save_dir=dataset.processed_dir) 
# Epoch: 01, Loss: 1.3690
# Epoch: 02, Loss: 0.5225
# ......
# Epoch: 29, Loss: 0.2164
# Evaluating: 100%|██████████| 465930/465930 [28:03<00:00, 276.69it/s]
# Epoch: 30, Loss: 0.2128, Train: 0.9740, Val: 0.9543, test: 0.9529

cluster_data = ClusterData(data, num_parts=2000, recursive=False, save_dir=dataset.processed_dir) 
# Epoch: 01, Loss: 1.0763
# Epoch: 02, Loss: 0.4746
# ......
# Epoch: 29, Loss: 0.2518
# Evaluating: 100%|██████████| 465930/465930 [28:03<00:00, 276.79it/s]
# Epoch: 30, Loss: 0.2501, Train: 0.9689, Val: 0.9531, test: 0.9507
```
聚类数目分别为1000、1500和2000时，测试集的准确率分别为0.9529、0.9513和0.9507。  
## 参考资料
1. [Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Network](https://arxiv.org/abs/1905.07953)  
2. [Daltawhale GNN组队学习开源教程](https://gitee.com/rongqinchen/team-learning-nlp/tree/master/GNN)  
3. [如何设置win10系统的虚拟内存](https://baijiahao.baidu.com/s?id=1621157354219504755&wfr=spider&for=pc)  
