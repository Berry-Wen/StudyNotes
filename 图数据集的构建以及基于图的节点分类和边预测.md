# 图数据集的构建以及基于图的节点分类和边预测
程序 = 数据结构 + 算法。若想使用 PyTorch geometric 中各种有用的模型和函数，数据集的结构必须符合 PyG 的既定标准，例如 PyG 自带的 Planetoid 等数据集类。为了处理自己独有的数据集，我们必须掌握如何将原始数据转化为对应的数据集类。  
PyG 构建数据集分两种， 一种继承 torch_geometric.data.InMemoryDataset，一次性加载所有数据到内存；另一种继承torch_geometric.data.Dataset, 分次加载到内存。对于占用内存有限的数据集，我们可以将所有数据都存储到内存里，通过继承 InMemoryDataset 去构建数据集类。  
在本文中，我们主要学习如何构建 InMemoryDataset 类，以及完成基于节点表征学习的图节点预测和边预测任务。  

## 图数据集构建：继承 InMemoryDataset 类
### 准备好原始的数据文件（raw）
在使用 Planetoid 中的数据集做练习的时候，我们发现程序会自动下载后缀为 'x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index' 的数据文件，然后将其处理为后缀为 'pt' 的数据文件，最后被读取成为能够被 Python 处理的  Data 对象。  
因此，我们必须需要了解原始的数据文件结构，才能知道如何转化、处理我们自己的数据集。  
```python
ind.dataset_str.x # the feature vectors of the training instances
ind.dataset_str.tx # the feature vectors of the test instances
ind.dataset_str.allx # the feature vectors of both labeled and unlabeled training instances (a superset of ind.dataset_str.x)
# The objects as scipy.sparse.csr.csr_matrix object 

ind.dataset_str.y # the one-hot labels of the labeled training instances 
ind.dataset_str.ty # the one-hot labels of the test instances
ind.dataset_str.ally # the labels for instances in ind.dataset_str.allx
# The objects as numpy.ndarray object

ind.dataset_str.graph # a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict object;

ind.dataset_str.test.index # the indices of test instances in graph, for the inductive setting as list object.

#All objects above must be saved using python pickle module.
#:param dataset_str: Dataset name
```
在准备好原始的数据文件后（下载或自己生成），我们就可以继续处理生成 Data 对象。如果我们将自己生成的原始数据文件放到网络上，也可以构建一个类似 Planetoid 的数据集类以方便使用。  
### InMemoryDataset 类简介
简介：创建在 CPU 内存里运行的图数据集的数据集基类  
父类：torch_geometric.data.dataset.Dataset  
类初始化及其参数说明：  
```python
CLASS InMemoryDataset(root: Optional[str] = None, transform: Optional[Callable] = None, pre_transform: Optional[Callable] = None, pre_filter: Optional[Callable] = None)
```
* `root`：字符串类型，存储数据集的文件夹的路径。该文件夹下有两个文件夹：  
    * 一个文件夹为记录在`raw_dir`，它用于存储未处理的文件，从网络上下载的数据集原始文件会被存放到这里；   
    * 另一个文件夹记录在`processed_dir`，处理后的数据被保存到这里，以后从此文件夹下加载文件即可获得 Data 对象。 
    * 注：raw_dir 和 processed_dir 是属性方法，我们可以自定义要使用的文件夹。  
    root 的目录结构如下图所示：  
    ![raw_processed](F:\学习总结\Method-and-Technology\images\raw_processed.png)  
    其他的重要参数如下（可不设置）：  
* `transform`：函数类型，一个数据转换函数。此函数在每一次数据获取过程中都会被执行。此函数应该用于数据增广（Data Augmentation）。  
* `pre_transform`：函数类型，一个数据转换函数。此函数在Data对象被保存到文件前调用。因此它应该用于只执行一次的数据预处理。  
* `pre_filter`：函数类型，一个检查数据是否要保留的函数。  

通过继承 InMemoryDataset 类来构造一个我们自己的数据集类，我们需要实现四个基本方法：  
* `raw_file_names()`：属性方法，返回一个数据集原始文件的文件名列表，数据集原始文件应该能在 `raw_dir` 文件夹中找到，否则调用 `download()` 函数下载文件到raw_dir文件夹。  
* `processed_file_names()`：属性方法，返回一个存储处理过的数据的文件的文件名列表，存储处理过的数据的文件应该能在 `processed_dir` 文件夹中找到，否则调用 process() 函数对样本做处理，然后保存处理过的数据到 `processed_dir` 文件夹下的文件里。  
* `download()`: 下载数据集原始文件到 `raw_dir` 文件夹。  
* `process()`: 处理数据，保存处理好的数据到 `processed_dir` 文件夹下的文件。  
其中，比较重要的，区分数据集类不同的是 download 和 process 函数，需要设定数据集的下载地址和数据处理方式。raw_file_names 和 processed_file_names 一般不变。   
### InMemoryDataset 数据集类实例
通过例子我们可以更快地掌握 InMemoryDataset 的使用方法和注意事项。我们将首先学习 PlanetoidPubMed 数据集类的构造，其次学习使用时会程序运行的过程。构造代码如下所示：  
```python
import os.path as osp
import torch
from torch_geometric.data import (InMemoryDataset, download_url)
from torch_geometric.io import read_planetoid_data

class PlanetoidPubMed(InMemoryDataset):
    url = 'https://github.com/kimiyoung/planetoid/raw/master/data'
    # url = 'https://gitee.com/rongqinchen/planetoid/raw/master/data'
    # 如果github的链接不可用，请使用gitee的链接

    def __init__(self, root, transform=None, pre_transform=None):
        super(PlanetoidPubMed, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0]) 
        # 在本实例中载入 data.pt 文件
        # processed_paths()属性方法是在基类中定义的，它对self.processed_dir文件夹与processed_file_names()属性方法的返回的每一个文件名做拼接，然后返回

    @property
    def raw_dir(self):
        return osp.join(self.root, 'raw')

    @property
    def processed_dir(self):
        return osp.join(self.root, 'processed')

    @property
    def raw_file_names(self):
        names = ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index']
        return ['ind.pubmed.{}'.format(name) for name in names] # 在下载链接里也存在 trans 为前缀的数据文献，不需要下载

    @property
    def processed_file_names(self):
        return 'data.pt'

    def download(self):
        for name in self.raw_file_names:
            download_url('{}/{}'.format(self.url, name), self.raw_dir)

    def process(self):
        data = read_planetoid_data(self.raw_dir, 'pubmed') # 
        data = data if self.pre_transform is None else self.pre_transform(data)
        torch.save(self.collate([data]), self.processed_paths[0])

    def __repr__(self):
        return '{}()'.format(self.name)
```
在我们生成一个 PlanetoidPubMed 类的对象时，程序运行流程如下：  
* 首先，检查数据原始文件是否已下载：  
    * 检查 self.raw_dir 目录下是否存在 raw_file_names() 属性方法返回的每个文件
    * 如有文件不存在，则调用 download() 方法执行原始文件的下载   
    * self.raw_dir 通过 osp.join(self.root, 'raw') 创建   
* 其次，检查数据是否经过处理：  
    * 检查self.processed_dir目录下是否存在pre_transform.pt文件：
        * 若存在，需要加载该文件，以获取之前所用的数据变换的方法，并检查它与当前pre_transform参数指定的方法是否相同，如果不相同则会报出一个警告
        * self.processed_dir 通过 osp.join(self.root, 'processed') 创建
    * 检查 self.processed_dir 目录下是否存在 pre_filter.pt 文件：
        * 如果存在，则加载该文件并获取之前所用的样本过滤的方法，并检查它与当前pre_filter参数指定的方法是否相同，如果不相同则会报出一个警告
    * 检查 self.processed_dir 目录下是否存在 self.processed_file_names 属性方法返回的所有文件（实例中只有data.pt），如有文件不存在，则需要执行以下的操作：
        * 调用process()方法，进行数据处理
        * 如果 pre_transform 不为 None，则调用pre_transform()函数进行数据处理
        * 如果 pre_filter 不为 None，则进行样本过滤
        * 保存处理好的数据到文件，文件存储在**processed_paths()**属性方法返回的文件路径。如果将数据保存到多个文件中，则返回的路径有多个
* 最后保存新的 pre_transform.pt 文件和pre_filter.pt文件，它们分别存储当前使用的数据处理方法和样本过滤方法。  
让我们来查看这个数据集：  
```python
dataset = PlanetoidPubMed('dataset/PlanetoidPubMed')
print(dataset.num_classes) # 3
print(dataset[0].num_nodes) # 19717
print(dataset[0].num_edges) # 88648
print(dataset[0].num_features) # 500
```
## 节点预测任务实践
我们使用之前定义好的 PlanetoidPubMed 数据集来实践节点预测任务。在数据集确定的前提下，在实践中，我们还需要确定的内容包括：训练集、验证集和测试集的划分，神经网络模型的结构（多少层，每一层有多少个神经元，每个神经元的结构是什么，激活函数和Dropout层的使用等）。  
### 划分训练集、验证集和测试集
我们在数据集类的定义中可以确定划分方式，如下所示：  
```python
class PlanetoidPubMed(InMemoryDataset): #省略与本文第一节的重复内容
    def __init__(self, root, split="public", num_train_per_class=20,
                 num_val=500, num_test=1000, transform=None,
                 pre_transform=None):
        super(PlanetoidPubMed, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

        self.split = split # 选择训练集的采样方式，默认为 public，按照二值掩码
        assert self.split in ['public', 'full', 'random']

        if split == 'full': # 重新设置二值掩码
            data = self.get(0)
            data.train_mask.fill_(True)
            data.train_mask[data.val_mask | data.test_mask] = False
            self.data, self.slices = self.collate([data])

        elif split == 'random': # 重新设置二值掩码
            data = self.get(0)
            data.train_mask.fill_(False)
            for c in range(self.num_classes):
                idx = (data.y == c).nonzero(as_tuple=False).view(-1)
                idx = idx[torch.randperm(idx.size(0))[:num_train_per_class]]
                data.train_mask[idx] = True

            remaining = (~data.train_mask).nonzero(as_tuple=False).view(-1)
            remaining = remaining[torch.randperm(remaining.size(0))]

            data.val_mask.fill_(False)
            data.val_mask[remaining[:num_val]] = True

            data.test_mask.fill_(False)
            data.test_mask[remaining[num_val:num_val + num_test]] = True

            self.data, self.slices = self.collate([data])
```
在本实例中，我们使用默认参数 “public” 对训练集等进行划分。  
### 构建图神经网络模型架构
之前我们学习 2 层 GATConv 组成的图神经网络，现在我们重定义一个 GAT 图神经网络，使其能够通过参数来定义 GATConv 的层数，以及每一层的 out_channels，如下所示：  
```python
class GAT(torch.nn.Module):
    def __init__(self, num_features, hidden_channels_list, num_classes):
        super(GAT, self).__init__()
        torch.manual_seed(12345) # 设置随机种子数，方便复现
        hns = [num_features] + hidden_channels_list # 列表合并
        conv_list = []
        for idx in range(len(hidden_channels_list)): # 注意range不包括最大值
            conv_list.append((GATConv(hns[idx], hns[idx+1]), 'x, edge_index -> x'))
            conv_list.append(ReLU(inplace=True),)

        self.convseq = Sequential('x, edge_index', conv_list) # 容器，方便处理重复的连续层
        self.linear = Linear(hidden_channels_list[-1], num_classes) # 最后一层需要分类，要使用线性层（softmax），之前的隐藏层主要目的是抽取特征

    def forward(self, x, edge_index):
        x = self.convseq(x, edge_index) # 利用容器一次性设置好多层的输入输出
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.linear(x)
        return x
```
### 模型训练和测试
使用 Adam 优化器估计参数，train 和 test 的函数定义不再赘述，基本没怎么变化。结果如下：  
```python
model = GAT(num_features=dataset.num_features, hidden_channels_list=[200, 100], num_classes=dataset.num_classes).to(device)
print(model)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

for epoch in range(1, 201):
    loss = train()
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')
# Epoch: 001, Loss: 1.0985
# Epoch: 002, Loss: 1.0935
# Epoch: 003, Loss: 1.0882
# ......
# Epoch: 198, Loss: 0.0196
# Epoch: 199, Loss: 0.0074
# Epoch: 200, Loss: 0.0100

test_acc = test()
print(f'Test Accuracy: {test_acc:.4f}')
# Test Accuracy: 0.7490
```
通过调整优化参数和神经网络结构，我们可以进一步改进模型预测性能。  
## 边预测任务实践
我们使用 Planetoid 中的 Cora 数据集来实践边预测任务。最大的不同的是分析对象是边，而不是节点，这需要我们重新定义训练集、测试集等，以及生成负样本等。图神经网络模型的结构和使用流程也与节点预测任务有很大不同。  
### 数据集获取及预处理
为了构建边预测任务，我们需要生成一些负样本，即采样一些不存在边的节点对作为负样本边，正负样本数量应平衡。此外要将样本分为训练集、验证集和测试集三个集合。  
PyG 为我们提供了采样负样本边的方法：  
```python 
train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1) 
```
该函数将自动地采样得到负样本，并将正负样本分成训练集、验证集和测试集三个集合。它用train_pos_edge_index、train_neg_adj_mask、val_pos_edge_index、val_neg_edge_index、test_pos_edge_index和test_neg_edge_index，六个属性取代edge_index属性。  
其中 train_neg_adj_mask 是节点数量 \* 节点数量的矩阵，True值代表行列对应的边未连接。  
实践中的代码如下：  
```python
import os.path as osp
from torch_geometric.utils import negative_sampling
from torch_geometric.datasets import Planetoid
import torch_geometric.transforms as T
from torch_geometric.utils import train_test_split_edges

dataset = Planetoid('dataset', 'Cora', transform=T.NormalizeFeatures())
data = dataset[0]
data.train_mask = data.val_mask = data.test_mask = data.y = None # 不再有用

print(data.edge_index.shape)
# torch.Size([2, 10556])

data = train_test_split_edges(data) # 重要步骤，生成负样本，划分训练集等

for key in data.keys:
    print(key, getattr(data, key).shape)

# x torch.Size([2708, 1433])
# val_pos_edge_index torch.Size([2, 263])
# test_pos_edge_index torch.Size([2, 527])
# train_pos_edge_index torch.Size([2, 8976])
# train_neg_adj_mask torch.Size([2708, 2708])
# val_neg_edge_index torch.Size([2, 263])
# test_neg_edge_index torch.Size([2, 527])
# 263 + 527 + 8976 = 9766 != 10556
# 263 + 527 + 8976/2 = 5278 = 10556/2
```
Cora图是无向图，在统计原始边数量时，每一条边的正向与反向各统计了一次，训练集也包含边的正向与反向，但验证集与测试集都只包含了边的一个方向。  
**为什么训练集要包含边的正向与反向，而验证集与测试集都只包含了边的一个方向？**这是因为，训练集用于训练，训练时一条边的两个端点要互传信息，只考虑一个方向的话，只能由一个端点传信息给另一个端点，而验证集与测试集的边用于衡量检验边预测的准确性，只需考虑一个方向的边即可。  
### 边预测神经网络的构造
边预测的神经网络主要由两部分组成：其一是编码（encode），用于生成节点表征，如下所示：  
![raw_processed](F:\学习总结\Method-and-Technology\images\GAE编码器.jpg)  
其二是解码（decode），它根据边两端节点的表征生成边为真的几率（odds），如下所示：  
![raw_processed](F:\学习总结\Method-and-Technology\images\GAE解码器.jpg)  
我们实践中使用 GCNConv 来构建边预测神经网络：  
```python
import torch
from torch_geometric.nn import GCNConv

class Net(torch.nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Net, self).__init__()
        self.conv1 = GCNConv(in_channels, 128)
        self.conv2 = GCNConv(128, out_channels)

    def encode(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        return self.conv2(x, edge_index)

    def decode(self, z, pos_edge_index, neg_edge_index):
        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)
        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()
```
decode_all(self, z)用于推理（inference）阶段，我们要对所有的节点对预测存在边的几率。  
### 边预测图神经网络的训练
定义单个epoch的训练过程：  
```python
def get_link_labels(pos_edge_index, neg_edge_index):
    num_links = pos_edge_index.size(1) + neg_edge_index.size(1)
    link_labels = torch.zeros(num_links, dtype=torch.float)
    link_labels[:pos_edge_index.size(1)] = 1. # 节点对-标签 结构
    return link_labels

def train(data, model, optimizer):
    model.train()

    neg_edge_index = negative_sampling(
        edge_index=data.train_pos_edge_index, # 正边，清除出负样本的选择范围
        num_nodes=data.num_nodes, # 节点数量，可分析出候选的边
        num_neg_samples=data.train_pos_edge_index.size(1)) # 保持正负平衡
    
    train_neg_edge_set = set(map(tuple, neg_edge_index.T.tolist()))
    val_pos_edge_set = set(map(tuple, data.val_pos_edge_index.T.tolist()))
    test_pos_edge_set = set(map(tuple, data.test_pos_edge_index.T.tolist()))
    if (len(train_neg_edge_set & val_pos_edge_set) > 0) or (len(train_neg_edge_set & test_pos_edge_set) > 0):
        # 训练集负样本与验证集负样本存在交集，或训练集负样本与测试集负样本存在交集
        print('wrong!')

    optimizer.zero_grad()
    z = model.encode(data.x, data.train_pos_edge_index) # 生成节点表征
    link_logits = model.decode(z, data.train_pos_edge_index, neg_edge_index) # 节点两两配对计算，生成链接概率
    link_labels = get_link_labels(data.train_pos_edge_index, neg_edge_index).to(data.x.device) # 真实的标签
    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)
    loss.backward()
    optimizer.step()

    return loss
```
与节点预测时的不同已在注释中进行说明。  
### 边预测图神经网络的测试
定义单个epoch的测试过程：  
```python
@torch.no_grad()
def test(data, model):
    model.eval()
    z = model.encode(data.x, data.train_pos_edge_index) #此时的data为测试集
    results = []
    for prefix in ['val', 'test']:
        pos_edge_index = data[f'{prefix}_pos_edge_index']
        neg_edge_index = data[f'{prefix}_neg_edge_index']
        link_logits = model.decode(z, pos_edge_index, neg_edge_index)
        link_probs = link_logits.sigmoid()
        link_labels = get_link_labels(pos_edge_index, neg_edge_index)
        results.append(roc_auc_score(link_labels.cpu(), link_probs.cpu()))
    return results
```
### 边预测图神经网络的性能评价
使用Adam作为参数优化器，运行100次epoch，而且在每次epoch都输出loss和性能指标。  
```python
model = Net(dataset.num_features, 64).to(device)
optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)

best_val_auc = test_auc = 0 # 寻找最优的验证和测试性能
for epoch in range(1, 101):
    loss = train(data, model, optimizer)
    val_auc, tmp_test_auc = test(data, model)
    if val_auc > best_val_auc:
        best_val_auc = val_auc
        test_auc = tmp_test_auc
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '
        f'Test: {test_auc:.4f}')
# Epoch: 001, Loss: 0.6930, Val: 0.6905, Test: 0.6984
# Epoch: 002, Loss: 0.6820, Val: 0.6830, Test: 0.6984
# ......
# Epoch: 099, Loss: 0.4440, Val: 0.8725, Test: 0.9064
# Epoch: 100, Loss: 0.4500, Val: 0.8736, Test: 0.9070

print(f'the best val_auc: {best_val_auc:.4f}')
# the best val_auc: 0.8736
print(f'the best test_auc: {test_auc:.4f}')
# the best test_auc: 0.9070
z = model.encode(data.x, data.train_pos_edge_index)
final_edge_index = model.decode_all(z)
# shape (2, 3343252)
```
## 作业实践
### 实践问题一：使用PyG中的不同的网络层、层数和不同的out_channels，来实现节点分类任务
更改图神经网络的定义和输入参数，分析不同设定对节点分类性能的影响。其中，将上文使用过的GAT层更改为GCN层，分析隐藏层为2,3,4，以及输出神经元个数为[200,100,50,25]时的性能。  
图神经网络模型的架构定义如下：  
```python
class GCN(torch.nn.Module):
    def __init__(self, num_features, hidden_channels_list, num_classes):
        super(GCN, self).__init__()
        torch.manual_seed(12345)
        hns = [num_features] + hidden_channels_list
        conv_list = []
        for idx in range(len(hidden_channels_list)):
            conv_list.append((GCNConv(hns[idx], hns[idx+1]), 'x, edge_index -> x'))
            conv_list.append(ReLU(inplace=True),)

        self.convseq = Sequential('x, edge_index', conv_list)
        self.linear = Linear(hidden_channels_list[-1], num_classes)

    def forward(self, x, edge_index):
        x = self.convseq(x, edge_index)
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.linear(x)
        return x
```
在模型初始化的时候，设定隐藏层的层数和神经元格式，然后训练测试，如下所示：  
```python
model = GCN(num_features=dataset.num_features, hidden_channels_list=[200, 100, 50, 25], num_classes=dataset.num_classes).to(device)
print(model)
# GCN((convseq): Sequential(
#   (0): GCNConv(500, 200)   (1): ReLU(inplace=True)
#   (2): GCNConv(200, 100)   (3): ReLU(inplace=True)
#   (4): GCNConv(100, 50)    (5): ReLU(inplace=True)
#   (6): GCNConv(50, 25)     (7): ReLU(inplace=True))
# (linear): Linear(in_features=25, out_features=3, bias=True))

optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

for epoch in range(1, 201):
    loss = train()
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')
# Epoch: 001, Loss: 1.1068
# Epoch: 002, Loss: 1.1029
# Epoch: 003, Loss: 1.0980
# ......
# Epoch: 199, Loss: 0.0193
# Epoch: 200, Loss: 0.0195

test_acc = test()
print(f'Test Accuracy: {test_acc:.4f}')
# Test Accuracy: 0.7380
```
### 实践问题二：在边预测任务中，尝试用torch_geometric.nn.Sequential容器构造图神经网络
修改之前边预测模型代码的 Net 类定义，如下所示：  
```python
class Net(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels_list, out_channels):
        super(Net, self).__init__()
        torch.manual_seed(12345)
        hns = [in_channels] + hidden_channels_list # 使用 hns 调整层数
        conv_list = []
        for idx in range(len(hidden_channels_list)):
            conv_list.append((GCNConv(hns[idx], hns[idx + 1]), 'x, edge_index -> x'))
            conv_list.append(ReLU(inplace=True), )
        self.convseq = Sequential('x, edge_index', conv_list)
        self.convEnd = GCNConv(hidden_channels_list[-1], out_channels)

    def encode(self, x, edge_index):
        x = self.convseq(x, edge_index)
        x = F.dropout(x, p=0.5, training=self.training)
        return self.convEnd(x, edge_index)

    def decode(self, z, pos_edge_index, neg_edge_index):
        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)
        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()
```
添加两层卷积后，训练测试，如下所示：  
```python
model = Net(dataset.num_features,[256, 128], 64).to(device) #
optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)

best_val_auc = test_auc = 0
for epoch in range(1, 101):
    loss = train(data, model, optimizer)
    val_auc, tmp_test_auc = test(data, model)
    if val_auc > best_val_auc:
        best_val_auc = val_auc
        test_auc = tmp_test_auc
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, 'f'Test: {test_auc:.4f}')
# Epoch: 001, Loss: 0.6931, Val: 0.6983, Test: 0.6831
# Epoch: 002, Loss: 0.6832, Val: 0.7030, Test: 0.7069
# ......
# Epoch: 100, Loss: 0.4636, Val: 0.8280, Test: 0.8325
```
### 思考问题三
如下方代码所示，我们以data.train_pos_edge_index为实际参数来进行训练集负样本采样，但这样采样得到的负样本可能包含一些验证集的正样本与测试集的正样本，即可能将真实的正样本标记为负样本，由此会产生冲突。但我们还是这么做，这是为什么？  
```python
neg_edge_index = negative_sampling(
    edge_index=data.train_pos_edge_index, num_nodes=data.num_nodes,
    num_neg_samples=data.train_pos_edge_index.size(1))
```
回答：为了保证真实性，因为实际上我们在训练模型的时候，是不知道验证集和测试集的信息的，所以不能假设已知哪些负样本可能是验证集和测试集的正样本。  

## 参考资料
* [GCN图卷积 utils.py脚本 by 布口袋\_天晴了](https://www.jianshu.com/p/2b87ebcc5644)  
* [Datawhale 开源GNN学习教程](https://gitee.com/rongqinchen/team-learning-nlp/tree/master/GNN/Markdown%E7%89%88%E6%9C%AC)